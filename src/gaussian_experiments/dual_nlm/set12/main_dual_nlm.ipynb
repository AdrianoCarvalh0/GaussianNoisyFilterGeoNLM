{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dual Non-Local Means: a two-stage information-theoretic filter for image denoising\n",
    "'''\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "import skimage\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "from skimage.filters.edges import convolve\n",
    "from skimage.transform import resize\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "from skimage.metrics import structural_similarity as SSIM\n",
    "from skimage.metrics import adapted_rand_error\n",
    "from skimage.metrics import variation_of_information\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral, denoise_wavelet, estimate_sigma)\n",
    "\n",
    "# Para evitar warning de divisão por zero\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "'''\n",
    "Parâmetros:\n",
    "\n",
    "\tP1m, P1v: patches centrais de referência das médias e variâncias\n",
    "\tP2m, P2v: patches das médias e variâncias pertencente a janela de busca\n",
    "'''\n",
    "def divergenciaKL(P1m, P1v, P2m, P2v):\n",
    "\n",
    "\t# Versão mais rápida de calcular\n",
    "\tdKL = np.sum( (1/(4*P1v*P2v))*( (P1v - P2v)**2 + ((P1m - P2m)**2)*(P1v + P2v) ) )\n",
    "\n",
    "\treturn dKL\n",
    "\n",
    "'''\n",
    "Parâmetros:\n",
    "\n",
    "\tP1m, P1v: patches centrais de referência das médias e variâncias\n",
    "\tP2m, P2v: patches das médias e variâncias pertencente a janela de busca\n",
    "'''\n",
    "def Bhattacharyya(P1m, P1v, P2m, P2v):\n",
    "\n",
    "\t# Calcula o coeficiente de Bhattacharyya (np.sum é aqui ou embaixo?)\n",
    "\tcBhat = np.sqrt( (2*np.sqrt(P1v)*np.sqrt(P2v)/(P1v + P2v) )*np.exp( -0.25* ( ((P1m - P2m)**2)/(P1v + P2v) ) ) )\n",
    "\t# Calcula distância de Bhattacharyya\n",
    "\tdBhat = np.sum( -np.log(cBhat) )\n",
    "\n",
    "\treturn dBhat\n",
    "\n",
    "'''\n",
    "Parâmetros:\n",
    "\n",
    "\tP1m, P1v: patches centrais de referência das médias e variâncias\n",
    "\tP2m, P2v: patches das médias e variâncias pertencente a janela de busca\n",
    "'''\n",
    "def Hellinger(P1m, P1v, P2m, P2v):\n",
    "\n",
    "\t# Calcula o coeficiente de Bhattacharyya (np.sum é aqui ou embaixo?)\n",
    "\tcBhat = np.sqrt( (2*np.sqrt(P1v)*np.sqrt(P2v)/(P1v + P2v) )*np.exp( -0.25* ( ((P1m - P2m)**2)/(P1v + P2v) ) ) )\n",
    "\t# Calcula distância de Hellinger\n",
    "\tdHell = np.sum( 1 - cBhat )\n",
    "\n",
    "\treturn dHell\n",
    "\n",
    "'''\n",
    "Parâmetros:\n",
    "\n",
    "\timg: imagem ruidosa de entrada\n",
    "\th: parâmetro que controla o grau de suavização (quanto maior, mais suaviza)\n",
    "\tf: tamanho do patch (2f + 1 x 2f + 1) -> se f = 3, então patch é 7 x 7\n",
    "\tt: tamanho da janela de busca (2t + 1 x 2t + 1) -> se t = 10, então janela de busca é 21 x 21\n",
    "\n",
    "'''\n",
    "def NLM_KL(img, h, f, t):\n",
    "\n",
    "\t# Dimenssões espaciais da imagem\n",
    "\tm, n = img.shape\n",
    "\n",
    "\t# Cria imagem de saída\n",
    "\tfiltrada = np.zeros((m, n))\n",
    "\n",
    "\t# Cria matrizes para armazenar médias e variâncias\n",
    "\tmatriz_m = np.zeros((m, n))\n",
    "\tmatriz_v = np.zeros((m, n))\n",
    "\n",
    "\t# Estima médias de maneira não-local\n",
    "\t# O parâmetro h dessa pré filtragem é diferente do h usado no filtro proposto! Em geral, bem maior!\n",
    "\n",
    "\t# Estima médias de maneira não local com NLM padrão\n",
    "\tmatriz_m = NLM(img, 70, 2, 3)\t\t# default = 70, testei 60 em alguns [50, 55, 60, 65, 70]\n",
    "\n",
    "\t# Problema de valor de contorno: replicar bordas\n",
    "\timg_n = np.pad(img, ((f, f), (f, f)), 'symmetric')\n",
    "\n",
    "\t# Estima variâncias locais\n",
    "\tfor i in range(m):\n",
    "\t\tfor j in range(n):\n",
    "\t\t\tim = i + f\n",
    "\t\t\tjn = j + f\n",
    "\t\t\tmatriz_v[i, j] = img_n[im-f:im+f+1, jn-f:jn+f+1].var()\n",
    "\n",
    "\t# Replica bordas\n",
    "\tmatriz_m = np.pad(matriz_m, ((f, f), (f, f)), 'symmetric')\n",
    "\tmatriz_v = np.pad(matriz_v, ((f, f), (f, f)), 'symmetric')\n",
    "\n",
    "\t# Loop principal do NLM\n",
    "\tfor i in range(m):\n",
    "\t\tfor j in range(n):\n",
    "\n",
    "\t\t\tim = i + f;   # compensar a borda adicionada artificialmente\n",
    "\t\t\tjn = j + f;   # compensar a borda adicionada artificialmente\n",
    "\n",
    "        \t# Obtém o patch ao redor do pixel corrente em matriz_m e matriz_v\n",
    "\t\t\tW1m = matriz_m[im-f:(im+f)+1, jn-f:(jn+f)+1]\n",
    "\t\t\tW1v = matriz_v[im-f:(im+f)+1, jn-f:(jn+f)+1]\n",
    "\n",
    "        \t# Calcula as bordas da janela de busca para o pixel corrente\n",
    "\t\t\trmin = max(im-t, f);  # linha inicial\n",
    "\t\t\trmax = min(im+t, m+f);  # linha final\n",
    "\t\t\tsmin = max(jn-t, f);  # coluna inicial\n",
    "\t\t\tsmax = min(jn+t, n+f);  # coluna final\n",
    "\n",
    "        \t# Calcula média ponderada\n",
    "\t\t\tNL = 0      # valor do pixel corrente filtrado\n",
    "\t\t\tZ = 0       # constante normalizadora\n",
    "\n",
    "        \t# Loop para todos os pixels da janela de busca\n",
    "\t\t\tfor r in range(rmin, rmax):\n",
    "\t\t\t\tfor s in range(smin, smax):\n",
    "\n",
    "                \t# Obtém o patch ao redor do pixel a ser comparado em matriz_m e matriz_v\n",
    "\t\t\t\t\tW2m = matriz_m[r-f:(r+f)+1, s-f:(s+f)+1]\n",
    "\t\t\t\t\tW2v = matriz_v[r-f:(r+f)+1, s-f:(s+f)+1]\n",
    "\n",
    "                \t# Calcula a divergência KL simetrizada\n",
    "\t\t\t\t\tdKL = divergenciaKL(W1m, W1v, W2m, W2v)\n",
    "\t\t\t\t\t#dKL = Bhattacharyya(W1m, W1v, W2m, W2v)\n",
    "\t\t\t\t\t#dKL = Hellinger(W1m, W1v, W2m, W2v)\n",
    "\n",
    "                \t# Calcula a medida de similaridade\n",
    "\t\t\t\t\tsij = np.exp(-dKL/(h**2))\n",
    "\n",
    "                \t# Atualiza Z e NL\n",
    "\t\t\t\t\tZ = Z + sij\n",
    "\t\t\t\t\tNL = NL + sij*img_n[r, s]\n",
    "\n",
    "        \t# Normalização do pixel filtrado\n",
    "\t\t\tfiltrada[i, j] = NL/Z\n",
    "\n",
    "\treturn filtrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17462265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%% Início do script\n",
    "\n",
    "# Imagens em tons de cinzas\n",
    "name = 'lena.bmp'\n",
    "\n",
    "# Lista de imagens\n",
    "lista = [name]\n",
    "\n",
    "# Aplica NLM-KL\n",
    "for nome in lista:\n",
    "\n",
    "\tprint('********** Imagem: %s' %nome)\n",
    "\n",
    "\timg = skimage.io.imread(nome)\n",
    "\n",
    "\t# Verifica se imagem é colorida (tem mais de um canal)\n",
    "\tif len(img.shape) > 2:\n",
    "\t\timg = skimage.color.rgb2gray(img)\n",
    "\t\timg = 255*img\n",
    "\t\t#img = img.astype(np.uint8)\n",
    "\n",
    "\t# Se imagem original não for uint8\n",
    "\tif img.max() > 255:\n",
    "\t\timg = img/img.max()\n",
    "\t\timg = 255*img\n",
    "\t\t#img = img.astype(np.uint8)\n",
    "\n",
    "\tm, n = img.shape\n",
    "\n",
    "\t# Setar para True para redimensionar as imagens para 128 x 128 (diminui custo computacional)\n",
    "\treshape = False\n",
    "\n",
    "\tif reshape:\n",
    "\t\t# Converte todas as imagens para 128 x 128\n",
    "\t\tif (m == 256) and (n == 256):\n",
    "\t\t\timg = resize(img, (m//2, n//2), anti_aliasing=False, preserve_range=True)\n",
    "\t\t\timg = img.astype(np.uint8)    # Converte para uint8    \n",
    "\t\telif (m == 512) and (n == 512):\n",
    "\t\t\timg = resize(img, (m//4, n//4), anti_aliasing=False, preserve_range=True)\n",
    "\t\t\timg = img.astype(np.uint8)    # Converte para uint8\n",
    "\t\telif (m == 1024) and (n == 1024):\n",
    "\t\t\timg = resize(img, (m//8, n//8), anti_aliasing=False, preserve_range=True)\n",
    "\t\t\timg = img.astype(np.uint8)    # Converte para uint8\t\t\n",
    "\telse:\n",
    "\t\timg = img.astype(np.uint8)\n",
    "\n",
    "\tm, n = img.shape\n",
    "\t# Desvio padrão do ruído\n",
    "\t\n",
    "\n",
    "\t# Parêmtros do NLM\n",
    "\tf = 4\t\n",
    "\tt = 7\t\n",
    "\n",
    "\t#%%%%%%%% Non-Local Means\n",
    "\t# O parâmetro h do filtro NLM_KL é diferente do utilizado na pré filtragem para obtenção das médias não locais\n",
    "\t# Em geral, é bem menor. (de 1.0 a 2.0. Controla a suavização (global)\n",
    "\tif f == 1:\n",
    "\t\tlista_h = [0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6] \t# 256 x 256, H = 50\n",
    "\telif f == 2:\n",
    "\t\tlista_h = [1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0] \t# 256 x 256, H = 60, 70  (*)\n",
    "\telif f == 3:\n",
    "\t\tlista_h = [2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8]\t\t# 256 x 256, H = 65, 70 \n",
    "\telif f == 4:\n",
    "\t\tlista_h = [2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3] \t\t\t\n",
    "\telif f == 5:\n",
    "\t\tlista_h = [3.6, 3.8, 4.0, 4.2, 4.4, 4.6] \t\t\t\t\t# 256 x 256\n",
    "\t\t\n",
    "\tprint('######### NLM-KL #################')\n",
    "\t\n",
    "\tinicio = time.time()\n",
    "\tfiltrada = NLM_KL(ruidosa, h=3.0, f=4, t=7)\n",
    "\tfim = time.time()\n",
    "\n",
    "\tprint('Tempo de execução: %.2f segundos' %(fim - inicio))\n",
    "\tprint('h = %.2f' %h)\n",
    "\n",
    "\t# Salva imagem no arquivo de saída\n",
    "\t# Converte para uint8 (8 bits)\n",
    "\toutput = filtrada.astype(np.uint8)\n",
    "\tfile = nome[14:]\n",
    "\tlimite = file.find('.')\n",
    "\tfilename = file[:limite] + '_NLM_KL_OK_' + str(h) + '.png'\n",
    "\tskimage.io.imsave(filename, output)\n",
    "\n",
    "\t# Calcula PSNR\n",
    "\tp = PSNR(img, output)\n",
    "\tprint('PSNR: %f' %p)\n",
    "\n",
    "\t# Calcula SSIM\n",
    "\ts = SSIM(img, output)\n",
    "\tprint('SSIM: %f' %s)\n",
    "\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73e453d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 3\u001b[0m PROJECT_ROOT \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(PROJECT_ROOT))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mGaussian_DUALNLM\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_gaussian_experiment_low_dual_nlm\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from Gaussian_DUALNLM import generate_gaussian_experiment_low_dual_nlm\n",
    "\n",
    "from functions.Utils import ensure_output_dirs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Base output directory for the low-noise experiment results\n",
    "    root_dir_output_low = Path('/workspace/data/output/set12/low_noisy') \n",
    "\n",
    "    # Directory containing the input images used in the experiment\n",
    "    dir_images_general = Path('/workspace/data/input/set12')\n",
    "\n",
    "    # Ensure required output directories exist\n",
    "    ensure_output_dirs(root_dir_output_low)\n",
    "\n",
    "    # Dictionary of parameters passed to the experiment generator\n",
    "    parameters = {\n",
    "\n",
    "        # Paths for reading input and saving results\n",
    "        'root_dir_output_low': str(root_dir_output_low),\n",
    "        'dir_images_general': str(dir_images_general),\n",
    "\n",
    "        # Output folders for each filtering method\n",
    "\n",
    "        'dir_out_dualnlm': str(root_dir_output_low / 'DUALNLM'),\n",
    "        'dir_out_results': str(root_dir_output_low / 'results'),\n",
    "\n",
    "        # Filenames for serialized results (pickle/XLSX)\n",
    "        'name_pickle_dual_nlm_output_low': 'array_dual_nlm_low_filtereds.pkl',    \n",
    "        'name_results_xlsx_dual_nlm_output_low':'dual_nlm_low_filtereds.xlsx',\n",
    "        'pickle_results_summary_low': '/workspace/data/output/set12/low_noisy/results/array_nln_low_filtereds.pkl',\n",
    "\n",
    "        # Algorithmic parameters used internally by the experiment\n",
    "        'f': 4,        # Patch radius\n",
    "        't': 7,        # Search window radius    \n",
    "    }\n",
    "\n",
    "    # Execute the low-noise Gaussian experiment\n",
    "    generate_gaussian_experiment_low_dual_nlm(parameters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
